#!/usr/bin/env python3
"""
Agent User Platform åç«¯æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•FastAPIåç«¯æœåŠ¡çš„å„é¡¹æ€§èƒ½æŒ‡æ ‡
"""

import asyncio
import time
import json
import statistics
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime
import aiohttp
import httpx
import psutil
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import matplotlib.pyplot as plt
import numpy as np

@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    name: str
    avg_response_time: float
    min_response_time: float
    max_response_time: float
    success_rate: float
    requests_per_second: float
    error_count: int
    total_requests: int
    response_times: List[float]
    timestamp: str

class BackendPerformanceTester:
    """åç«¯æ€§èƒ½æµ‹è¯•å™¨"""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url.rstrip('/')
        self.results: Dict[str, TestResult] = {}
        self.system_metrics: List[Dict[str, Any]] = []
        self.monitoring = False
        self.monitoring_thread = None

    async def start_system_monitoring(self):
        """å¯åŠ¨ç³»ç»Ÿèµ„æºç›‘æ§"""
        self.monitoring = True
        self.monitoring_thread = threading.Thread(target=self._monitor_system_resources)
        self.monitoring_thread.daemon = True
        self.monitoring_thread.start()

    def stop_system_monitoring(self):
        """åœæ­¢ç³»ç»Ÿèµ„æºç›‘æ§"""
        self.monitoring = False
        if self.monitoring_thread:
            self.monitoring_thread.join()

    def _monitor_system_resources(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        while self.monitoring:
            try:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory = psutil.virtual_memory()
                disk = psutil.disk_usage('/')

                metrics = {
                    'timestamp': datetime.now().isoformat(),
                    'cpu_percent': cpu_percent,
                    'memory_percent': memory.percent,
                    'memory_used_gb': memory.used / (1024**3),
                    'memory_available_gb': memory.available / (1024**3),
                    'disk_percent': disk.percent,
                    'disk_used_gb': disk.used / (1024**3),
                    'disk_free_gb': disk.free / (1024**3)
                }

                self.system_metrics.append(metrics)

            except Exception as e:
                print(f"ç›‘æ§é”™è¯¯: {e}")

            time.sleep(5)  # æ¯5ç§’æ”¶é›†ä¸€æ¬¡

    async def test_api_endpoints(self) -> Dict[str, TestResult]:
        """æµ‹è¯•APIç«¯ç‚¹æ€§èƒ½"""
        print("ğŸš€ å¼€å§‹APIç«¯ç‚¹æ€§èƒ½æµ‹è¯•...")

        # æµ‹è¯•ç”¨ä¾‹å®šä¹‰
        test_cases = [
            {
                "name": "ç”¨æˆ·æ³¨å†Œ",
                "method": "POST",
                "url": f"{self.base_url}/api/auth/register",
                "data": {
                    "email": f"test_{int(time.time())}@example.com",
                    "password": "test123456",
                    "username": f"testuser_{int(time.time())}"
                },
                "headers": {"Content-Type": "application/json"}
            },
            {
                "name": "ç”¨æˆ·ç™»å½•",
                "method": "POST",
                "url": f"{self.base_url}/api/auth/login",
                "data": {
                    "email": "test@example.com",
                    "password": "test123456"
                },
                "headers": {"Content-Type": "application/json"}
            },
            {
                "name": "è·å–Agentåˆ—è¡¨",
                "method": "GET",
                "url": f"{self.base_url}/api/agents",
                "headers": {}
            },
            {
                "name": "åˆ›å»ºAgent",
                "method": "POST",
                "url": f"{self.base_url}/api/agents",
                "data": {
                    "description": "æµ‹è¯•Agent - ç”¨äºæ€§èƒ½æµ‹è¯•",
                    "name": f"test_agent_{int(time.time())}"
                },
                "headers": {"Content-Type": "application/json"}
            },
            {
                "name": "è·å–å·¥ä½œæµåˆ—è¡¨",
                "method": "GET",
                "url": f"{self.base_url}/api/workflows",
                "headers": {}
            },
            {
                "name": "åˆ›å»ºå·¥ä½œæµ",
                "method": "POST",
                "url": f"{self.base_url}/api/workflows",
                "data": {
                    "name": f"test_workflow_{int(time.time())}",
                    "description": "æµ‹è¯•å·¥ä½œæµ",
                    "nodes": [],
                    "edges": []
                },
                "headers": {"Content-Type": "application/json"}
            }
        ]

        # é¦–å…ˆè·å–è®¤è¯token
        token = await self._get_auth_token()
        if token:
            for test_case in test_cases:
                if test_case["name"] != "ç”¨æˆ·æ³¨å†Œ" and test_case["name"] != "ç”¨æˆ·ç™»å½•":
                    test_case["headers"]["Authorization"] = f"Bearer {token}"

        # å¹¶å‘æµ‹è¯•æ¯ä¸ªç«¯ç‚¹
        for test_case in test_cases:
            result = await self._test_single_endpoint(test_case)
            self.results[test_case["name"]] = result

        return self.results

    async def _get_auth_token(self) -> str:
        """è·å–è®¤è¯tokenç”¨äºåç»­æµ‹è¯•"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.base_url}/api/auth/login",
                    json={"email": "test@example.com", "password": "test123456"},
                    timeout=30.0
                )
                if response.status_code == 200:
                    return response.json().get("access_token", "")
        except Exception as e:
            print(f"è·å–tokenå¤±è´¥: {e}")
        return ""

    async def _test_single_endpoint(self, test_case: Dict, num_requests: int = 50) -> TestResult:
        """æµ‹è¯•å•ä¸ªAPIç«¯ç‚¹"""
        print(f"  æµ‹è¯• {test_case['name']}...")

        response_times = []
        error_count = 0
        success_count = 0

        start_time = time.time()

        async with httpx.AsyncClient(timeout=30.0) as client:
            tasks = []

            for i in range(num_requests):
                task = self._make_single_request(client, test_case, i)
                tasks.append(task)

            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è¯·æ±‚
            results = await asyncio.gather(*tasks, return_exceptions=True)

            for result in results:
                if isinstance(result, Exception):
                    error_count += 1
                else:
                    if result["success"]:
                        response_times.append(result["response_time"])
                        success_count += 1
                    else:
                        error_count += 1

        end_time = time.time()
        total_time = end_time - start_time

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        if response_times:
            avg_response_time = statistics.mean(response_times)
            min_response_time = min(response_times)
            max_response_time = max(response_times)
        else:
            avg_response_time = min_response_time = max_response_time = 0

        success_rate = success_count / num_requests if num_requests > 0 else 0
        requests_per_second = num_requests / total_time if total_time > 0 else 0

        result = TestResult(
            name=test_case["name"],
            avg_response_time=avg_response_time,
            min_response_time=min_response_time,
            max_response_time=max_response_time,
            success_rate=success_rate,
            requests_per_second=requests_per_second,
            error_count=error_count,
            total_requests=num_requests,
            response_times=response_times,
            timestamp=datetime.now().isoformat()
        )

        print(f"    âœ… å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ms")
        print(f"    âœ… æˆåŠŸç‡: {success_rate:.2%}")
        print(f"    âœ… è¯·æ±‚é€Ÿåº¦: {requests_per_second:.2f} req/s")

        return result

    async def _make_single_request(self, client: httpx.AsyncClient, test_case: Dict, request_id: int) -> Dict:
        """æ‰§è¡Œå•ä¸ªHTTPè¯·æ±‚"""
        start_time = time.time()

        try:
            if test_case["method"] == "GET":
                response = await client.get(test_case["url"], headers=test_case.get("headers", {}))
            elif test_case["method"] == "POST":
                response = await client.post(
                    test_case["url"],
                    json=test_case.get("data"),
                    headers=test_case.get("headers", {})
                )
            elif test_case["method"] == "PUT":
                response = await client.put(
                    test_case["url"],
                    json=test_case.get("data"),
                    headers=test_case.get("headers", {})
                )
            elif test_case["method"] == "DELETE":
                response = await client.delete(test_case["url"], headers=test_case.get("headers", {}))
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„HTTPæ–¹æ³•: {test_case['method']}")

            response_time = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

            return {
                "success": 200 <= response.status_code < 300,
                "response_time": response_time,
                "status_code": response.status_code,
                "request_id": request_id
            }

        except Exception as e:
            response_time = (time.time() - start_time) * 1000
            print(f"    âš ï¸ è¯·æ±‚å¤±è´¥: {e}")
            return {
                "success": False,
                "response_time": response_time,
                "error": str(e),
                "request_id": request_id
            }

    async def test_concurrent_load(self, concurrent_users: int = 100, test_duration: int = 60) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘è´Ÿè½½èƒ½åŠ›"""
        print(f"ğŸ”¥ å¼€å§‹å¹¶å‘è´Ÿè½½æµ‹è¯• - {concurrent_users} å¹¶å‘ç”¨æˆ·, {test_duration}ç§’...")

        results = {
            "concurrent_users": concurrent_users,
            "test_duration": test_duration,
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "avg_response_time": 0,
            "min_response_time": float('inf'),
            "max_response_time": 0,
            "requests_per_second": 0,
            "error_rate": 0,
            "response_time_percentiles": {},
            "timestamp": datetime.now().isoformat()
        }

        all_response_times = []

        async def user_simulation(user_id: int):
            """æ¨¡æ‹Ÿå•ä¸ªç”¨æˆ·è¡Œä¸º"""
            user_results = {
                "requests": 0,
                "successful_requests": 0,
                "response_times": []
            }

            async with httpx.AsyncClient(timeout=30.0) as client:
                end_time = time.time() + test_duration

                while time.time() < end_time:
                    try:
                        # æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºåºåˆ—
                        actions = [
                            ("GET", f"{self.base_url}/api/agents"),
                            ("POST", f"{self.base_url}/api/agents", {"description": f"æµ‹è¯•Agent {user_id}"}),
                            ("GET", f"{self.base_url}/api/workflows"),
                            ("GET", f"{self.base_url}/api/health")
                        ]

                        for method, url, *data in actions:
                            start_time = time.time()

                            try:
                                if method == "GET":
                                    response = await client.get(url)
                                elif method == "POST":
                                    response = await client.post(url, json=data[0] if data else {})

                                response_time = (time.time() - start_time) * 1000

                                user_results["requests"] += 1
                                user_results["response_times"].append(response_time)

                                if 200 <= response.status_code < 300:
                                    user_results["successful_requests"] += 1

                                # éšæœºç­‰å¾…ï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
                                await asyncio.sleep(np.random.uniform(0.5, 2.0))

                            except Exception as e:
                                print(f"ç”¨æˆ· {user_id} è¯·æ±‚å¤±è´¥: {e}")
                                continue

                    except Exception as e:
                        print(f"ç”¨æˆ· {user_id} æ¨¡æ‹Ÿå¤±è´¥: {e}")
                        continue

            return user_results

        # å¯åŠ¨æ‰€æœ‰ç”¨æˆ·æ¨¡æ‹Ÿ
        start_time = time.time()
        tasks = [user_simulation(i) for i in range(concurrent_users)]
        user_results = await asyncio.gather(*tasks)
        end_time = time.time()

        # æ±‡æ€»ç»“æœ
        total_requests = 0
        successful_requests = 0
        all_response_times = []

        for user_result in user_results:
            total_requests += user_result["requests"]
            successful_requests += user_result["successful_requests"]
            all_response_times.extend(user_result["response_times"])

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        if all_response_times:
            results["total_requests"] = total_requests
            results["successful_requests"] = successful_requests
            results["failed_requests"] = total_requests - successful_requests
            results["avg_response_time"] = statistics.mean(all_response_times)
            results["min_response_time"] = min(all_response_times)
            results["max_response_time"] = max(all_response_times)
            results["requests_per_second"] = total_requests / (end_time - start_time)
            results["error_rate"] = (total_requests - successful_requests) / total_requests if total_requests > 0 else 0

            # è®¡ç®—ç™¾åˆ†ä½æ•°
            all_response_times.sort()
            results["response_time_percentiles"] = {
                "p50": np.percentile(all_response_times, 50),
                "p75": np.percentile(all_response_times, 75),
                "p90": np.percentile(all_response_times, 90),
                "p95": np.percentile(all_response_times, 95),
                "p99": np.percentile(all_response_times, 99)
            }

        print(f"    âœ… æ€»è¯·æ±‚æ•°: {total_requests}")
        print(f"    âœ… æˆåŠŸè¯·æ±‚: {successful_requests}")
        print(f"    âœ… å¹³å‡å“åº”æ—¶é—´: {results['avg_response_time']:.2f}ms")
        print(f"    âœ… è¯·æ±‚é€Ÿåº¦: {results['requests_per_second']:.2f} req/s")
        print(f"    âœ… é”™è¯¯ç‡: {results['error_rate']:.2%}")

        return results

    async def test_database_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½"""
        print("ğŸ—„ï¸ å¼€å§‹æ•°æ®åº“æ€§èƒ½æµ‹è¯•...")

        # è¿™ä¸ªæµ‹è¯•éœ€è¦åç«¯é…åˆï¼Œè¿™é‡Œæ¨¡æ‹Ÿä¸€äº›å¸¸è§çš„æ•°æ®åº“æ“ä½œ
        results = {
            "timestamp": datetime.now().isoformat(),
            "tests": []
        }

        db_tests = [
            {
                "name": "AgentæŸ¥è¯¢æ€§èƒ½",
                "endpoint": "/api/agents",
                "method": "GET",
                "iterations": 100
            },
            {
                "name": "å·¥ä½œæµæŸ¥è¯¢æ€§èƒ½",
                "endpoint": "/api/workflows",
                "method": "GET",
                "iterations": 100
            },
            {
                "name": "ç”¨æˆ·æŸ¥è¯¢æ€§èƒ½",
                "endpoint": "/api/users",
                "method": "GET",
                "iterations": 100
            }
        ]

        for test in db_tests:
            print(f"  æµ‹è¯• {test['name']}...")

            response_times = []
            error_count = 0

            async with httpx.AsyncClient(timeout=30.0) as client:
                for i in range(test["iterations"]):
                    try:
                        start_time = time.time()

                        if test["method"] == "GET":
                            response = await client.get(f"{self.base_url}{test['endpoint']}")

                        response_time = (time.time() - start_time) * 1000

                        if 200 <= response.status_code < 300:
                            response_times.append(response_time)
                        else:
                            error_count += 1

                    except Exception as e:
                        error_count += 1
                        continue

            if response_times:
                test_result = {
                    "name": test["name"],
                    "avg_response_time": statistics.mean(response_times),
                    "min_response_time": min(response_times),
                    "max_response_time": max(response_times),
                    "response_time_std": statistics.stdev(response_times) if len(response_times) > 1 else 0,
                    "success_rate": (test["iterations"] - error_count) / test["iterations"],
                    "iterations": test["iterations"],
                    "error_count": error_count
                }

                results["tests"].append(test_result)

                print(f"    âœ… å¹³å‡å“åº”æ—¶é—´: {test_result['avg_response_time']:.2f}ms")
                print(f"    âœ… æˆåŠŸç‡: {test_result['success_rate']:.2%}")

        return results

    def generate_performance_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "base_url": self.base_url,
            "summary": {
                "total_endpoints_tested": len(self.results),
                "avg_response_time": self._calculate_overall_avg_response_time(),
                "min_response_time": self._calculate_overall_min_response_time(),
                "max_response_time": self._calculate_overall_max_response_time(),
                "overall_success_rate": self._calculate_overall_success_rate()
            },
            "api_performance": {
                endpoint: {
                    "avg_response_time": result.avg_response_time,
                    "min_response_time": result.min_response_time,
                    "max_response_time": result.max_response_time,
                    "success_rate": result.success_rate,
                    "requests_per_second": result.requests_per_second,
                    "error_count": result.error_count,
                    "total_requests": result.total_requests
                }
                for endpoint, result in self.results.items()
            },
            "system_metrics": self.system_metrics,
            "recommendations": self._generate_recommendations()
        }

        return report

    def _calculate_overall_avg_response_time(self) -> float:
        """è®¡ç®—æ•´ä½“å¹³å‡å“åº”æ—¶é—´"""
        if not self.results:
            return 0

        response_times = [result.avg_response_time for result in self.results.values()]
        return statistics.mean(response_times)

    def _calculate_overall_min_response_time(self) -> float:
        """è®¡ç®—æ•´ä½“æœ€å°å“åº”æ—¶é—´"""
        if not self.results:
            return 0

        min_times = [result.min_response_time for result in self.results.values()]
        return min(min_times)

    def _calculate_overall_max_response_time(self) -> float:
        """è®¡ç®—æ•´ä½“æœ€å¤§å“åº”æ—¶é—´"""
        if not self.results:
            return 0

        max_times = [result.max_response_time for result in self.results.values()]
        return max(max_times)

    def _calculate_overall_success_rate(self) -> float:
        """è®¡ç®—æ•´ä½“æˆåŠŸç‡"""
        if not self.results:
            return 0

        success_rates = [result.success_rate for result in self.results.values()]
        return statistics.mean(success_rates)

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åŸºäºæµ‹è¯•ç»“æœç”Ÿæˆå»ºè®®
        if self.results:
            # æ£€æŸ¥å“åº”æ—¶é—´
            slow_endpoints = [
                name for name, result in self.results.items()
                if result.avg_response_time > 1000  # å¤§äº1ç§’
            ]

            if slow_endpoints:
                recommendations.append(
                    f"âš ï¸  å‘ç°æ…¢å“åº”ç«¯ç‚¹: {', '.join(slow_endpoints)}ã€‚"
                    f"å»ºè®®ä¼˜åŒ–è¿™äº›ç«¯ç‚¹çš„æ€§èƒ½ï¼Œç›®æ ‡å“åº”æ—¶é—´åº”å°äº500msã€‚"
                )

            # æ£€æŸ¥æˆåŠŸç‡
            low_success_rate_endpoints = [
                name for name, result in self.results.items()
                if result.success_rate < 0.95  # æˆåŠŸç‡ä½äº95%
            ]

            if low_success_rate_endpoints:
                recommendations.append(
                    f"âš ï¸  å‘ç°æˆåŠŸç‡è¾ƒä½çš„ç«¯ç‚¹: {', '.join(low_success_rate_endpoints)}ã€‚"
                    f"å»ºè®®æ£€æŸ¥é”™è¯¯æ—¥å¿—å¹¶ä¿®å¤ç›¸å…³é—®é¢˜ã€‚"
                )

            # æ£€æŸ¥é”™è¯¯æ•°é‡
            high_error_endpoints = [
                name for name, result in self.results.items()
                if result.error_count > result.total_requests * 0.1  # é”™è¯¯ç‡è¶…è¿‡10%
            ]

            if high_error_endpoints:
                recommendations.append(
                    f"âš ï¸  å‘ç°é”™è¯¯ç‡è¾ƒé«˜çš„ç«¯ç‚¹: {', '.join(high_error_endpoints)}ã€‚"
                    f"å»ºè®®å¢åŠ é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶ã€‚"
                )

        # ç³»ç»Ÿèµ„æºå»ºè®®
        if self.system_metrics:
            latest_metrics = self.system_metrics[-1]

            if latest_metrics["cpu_percent"] > 80:
                recommendations.append(
                    "âš ï¸  CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–ä»£ç æˆ–å¢åŠ æœåŠ¡å™¨èµ„æºã€‚"
                )

            if latest_metrics["memory_percent"] > 80:
                recommendations.append(
                    "âš ï¸  å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼æˆ–å¢åŠ å†…å­˜ã€‚"
                )

        if not recommendations:
            recommendations.append("âœ… ç³»ç»Ÿæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œæš‚æ— ä¼˜åŒ–å»ºè®®ã€‚")

        return recommendations

    def save_report(self, filename: str = None):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if filename is None:
            filename = f"backend_performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        report = self.generate_performance_report()

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“Š æ€§èƒ½æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename

    def plot_performance_charts(self):
        """ç”Ÿæˆæ€§èƒ½å›¾è¡¨"""
        if not self.results:
            print("æ²¡æœ‰æµ‹è¯•ç»“æœå¯ç”¨äºç”Ÿæˆå›¾è¡¨")
            return

        # APIå“åº”æ—¶é—´å¯¹æ¯”å›¾
        plt.figure(figsize=(12, 8))

        endpoints = list(self.results.keys())
        avg_times = [self.results[ep].avg_response_time for ep in endpoints]
        min_times = [self.results[ep].min_response_time for ep in endpoints]
        max_times = [self.results[ep].max_response_time for ep in endpoints]

        x = np.arange(len(endpoints))
        width = 0.25

        plt.bar(x - width, min_times, width, label='æœ€å°å“åº”æ—¶é—´', alpha=0.8)
        plt.bar(x, avg_times, width, label='å¹³å‡å“åº”æ—¶é—´', alpha=0.8)
        plt.bar(x + width, max_times, width, label='æœ€å¤§å“åº”æ—¶é—´', alpha=0.8)

        plt.xlabel('APIç«¯ç‚¹')
        plt.ylabel('å“åº”æ—¶é—´ (ms)')
        plt.title('APIç«¯ç‚¹å“åº”æ—¶é—´å¯¹æ¯”')
        plt.xticks(x, endpoints, rotation=45, ha='right')
        plt.legend()
        plt.tight_layout()

        chart_filename = f"api_response_times_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(chart_filename, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"ğŸ“ˆ APIå“åº”æ—¶é—´å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_filename}")

        # ç³»ç»Ÿèµ„æºä½¿ç”¨å›¾
        if self.system_metrics:
            plt.figure(figsize=(12, 6))

            timestamps = [m['timestamp'] for m in self.system_metrics]
            cpu_usage = [m['cpu_percent'] for m in self.system_metrics]
            memory_usage = [m['memory_percent'] for m in self.system_metrics]

            plt.subplot(2, 1, 1)
            plt.plot(timestamps, cpu_usage, label='CPUä½¿ç”¨ç‡ (%)', color='red')
            plt.ylabel('CPUä½¿ç”¨ç‡ (%)')
            plt.title('ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ')
            plt.legend()
            plt.xticks(rotation=45)

            plt.subplot(2, 1, 2)
            plt.plot(timestamps, memory_usage, label='å†…å­˜ä½¿ç”¨ç‡ (%)', color='blue')
            plt.ylabel('å†…å­˜ä½¿ç”¨ç‡ (%)')
            plt.xlabel('æ—¶é—´')
            plt.legend()
            plt.xticks(rotation=45)

            plt.tight_layout()

            system_chart_filename = f"system_resources_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(system_chart_filename, dpi=300, bbox_inches='tight')
            plt.close()

            print(f"ğŸ“ˆ ç³»ç»Ÿèµ„æºä½¿ç”¨å›¾è¡¨å·²ä¿å­˜åˆ°: {system_chart_filename}")

async def run_backend_performance_test():
    """è¿è¡Œå®Œæ•´çš„åç«¯æ€§èƒ½æµ‹è¯•"""
    print("ğŸ¯ å¼€å§‹Agent User Platformåç«¯æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    tester = BackendPerformanceTester()

    try:
        # å¯åŠ¨ç³»ç»Ÿç›‘æ§
        await tester.start_system_monitoring()

        # 1. APIç«¯ç‚¹æ€§èƒ½æµ‹è¯•
        print("\nğŸ“‹ ç¬¬ä¸€é˜¶æ®µ: APIç«¯ç‚¹æ€§èƒ½æµ‹è¯•")
        api_results = await tester.test_api_endpoints()

        # 2. å¹¶å‘è´Ÿè½½æµ‹è¯•
        print("\nğŸ“‹ ç¬¬äºŒé˜¶æ®µ: å¹¶å‘è´Ÿè½½æµ‹è¯•")
        load_test_results = await tester.test_concurrent_load(concurrent_users=50, test_duration=30)

        # 3. æ•°æ®åº“æ€§èƒ½æµ‹è¯•
        print("\nğŸ“‹ ç¬¬ä¸‰é˜¶æ®µ: æ•°æ®åº“æ€§èƒ½æµ‹è¯•")
        db_results = await tester.test_database_performance()

        # åœæ­¢ç³»ç»Ÿç›‘æ§
        tester.stop_system_monitoring()

        # ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“‹ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        report_filename = tester.save_report()

        # ç”Ÿæˆå›¾è¡¨
        print("\nğŸ“‹ ç”Ÿæˆæ€§èƒ½å›¾è¡¨...")
        tester.plot_performance_charts()

        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ¯ åç«¯æ€§èƒ½æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")

        # æ‰“å°å…³é”®æŒ‡æ ‡
        report = tester.generate_performance_report()
        print(f"\nğŸ“ˆ å…³é”®æ€§èƒ½æŒ‡æ ‡:")
        print(f"   å¹³å‡APIå“åº”æ—¶é—´: {report['summary']['avg_response_time']:.2f}ms")
        print(f"   æ•´ä½“æˆåŠŸç‡: {report['summary']['overall_success_rate']:.2%}")
        print(f"   æœ€å°å“åº”æ—¶é—´: {report['summary']['min_response_time']:.2f}ms")
        print(f"   æœ€å¤§å“åº”æ—¶é—´: {report['summary']['max_response_time']:.2f}ms")
        print(f"   å¹¶å‘å¤„ç†èƒ½åŠ›: {load_test_results['requests_per_second']:.2f} req/s")

        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for recommendation in report['recommendations']:
            print(f"   {recommendation}")

        return {
            "api_performance": api_results,
            "load_test": load_test_results,
            "database_performance": db_results,
            "system_metrics": tester.system_metrics,
            "report": report
        }

    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        raise e
    finally:
        tester.stop_system_monitoring()

if __name__ == "__main__":
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    asyncio.run(run_backend_performance_test())